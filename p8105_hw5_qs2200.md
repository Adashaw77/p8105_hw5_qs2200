P8105\_hw5\_qs2200
================
Qi Shao
11/6/2018

Problem 1
---------

### Dataframe contains file names

``` r
zip_file = tibble(file_name = list.files("./data/problem1"))
zip_file
```

    ## # A tibble: 20 x 1
    ##    file_name 
    ##    <chr>     
    ##  1 con_01.csv
    ##  2 con_02.csv
    ##  3 con_03.csv
    ##  4 con_04.csv
    ##  5 con_05.csv
    ##  6 con_06.csv
    ##  7 con_07.csv
    ##  8 con_08.csv
    ##  9 con_09.csv
    ## 10 con_10.csv
    ## 11 exp_01.csv
    ## 12 exp_02.csv
    ## 13 exp_03.csv
    ## 14 exp_04.csv
    ## 15 exp_05.csv
    ## 16 exp_06.csv
    ## 17 exp_07.csv
    ## 18 exp_08.csv
    ## 19 exp_09.csv
    ## 20 exp_10.csv

### Read data

``` r
read_file = function(x){
  
  x = str_c("./data/problem1/", x)
  read_csv(x)
  
}

zip_file = 
  zip_file %>%
  mutate(data = map(zip_file$file_name, read_file))
```

### Tidy data

``` r
zip_file = 
  unnest(zip_file) %>%
  separate(file_name, into =c("arm", "id"), sep = "_") %>%
  separate(id, into =c("id", "other"), sep = ".csv") %>%
  gather(key = week, value = observation, week_1:week_8) %>%
  separate(week, into = c("rm", "week"), sep = "_") %>%
  select(-other, -rm )
```

### Make a spaghetti plot

``` r
zip_file %>%
  mutate(week = as.numeric(week))%>%
  ggplot(aes(x = week, y = observation, color = id)) +
  geom_line()+
  facet_grid(~arm)+
  viridis::scale_color_viridis(
    name = "ID", 
    discrete = TRUE
  )+
  theme_minimal() 
```

![](p8105_hw5_qs2200_files/figure-markdown_github/problem%201.4-1.png)

From this spaghetti plot, we can see that the observations of control arm remain stable during the 8 weeks, but in experimental arm, the value of observations rise obviously as time went on. So we can conclude that there is a association between experiment variable and observation.

Problem 2
---------

### Describe the raw data

``` r
read_csv("./data/homicide-data.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_integer(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

    ## # A tibble: 52,179 x 12
    ##    uid   reported_date victim_last victim_first victim_race victim_age
    ##    <chr>         <int> <chr>       <chr>        <chr>       <chr>     
    ##  1 Alb-…      20100504 GARCIA      JUAN         Hispanic    78        
    ##  2 Alb-…      20100216 MONTOYA     CAMERON      Hispanic    17        
    ##  3 Alb-…      20100601 SATTERFIELD VIVIANA      White       15        
    ##  4 Alb-…      20100101 MENDIOLA    CARLOS       Hispanic    32        
    ##  5 Alb-…      20100102 MULA        VIVIAN       White       72        
    ##  6 Alb-…      20100126 BOOK        GERALDINE    White       91        
    ##  7 Alb-…      20100127 MALDONADO   DAVID        Hispanic    52        
    ##  8 Alb-…      20100127 MALDONADO   CONNIE       Hispanic    52        
    ##  9 Alb-…      20100130 MARTIN-LEY… GUSTAVO      White       56        
    ## 10 Alb-…      20100210 HERRERA     ISRAEL       Hispanic    43        
    ## # ... with 52,169 more rows, and 6 more variables: victim_sex <chr>,
    ## #   city <chr>, state <chr>, lat <dbl>, lon <dbl>, disposition <chr>

### Tidy and summarise the data

``` r
homi_df = 
  read_csv("./data/homicide-data.csv") %>%
  mutate(city_state = str_c(city, ", ", state)) %>%
  group_by(city_state, disposition) %>%
  summarise(total= n()) %>%
  spread(key = disposition, value = total) %>%
  janitor::clean_names() %>%
  mutate(total_homi = rowSums(cbind(closed_by_arrest, closed_without_arrest, open_no_arrest), na.rm = T), unsolve_homi = rowSums(cbind(closed_without_arrest, open_no_arrest), na.rm = T)) %>%
  select(- closed_by_arrest, - closed_without_arrest, -open_no_arrest)
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_integer(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

### Estimate the proportion of unsolved homicides in Baltimore

``` r
baltimore_df = 
  homi_df %>%
  filter(city_state == "Baltimore, MD")

broom::tidy(prop.test(baltimore_df$unsolve_homi, baltimore_df$total_homi)) %>%
  knitr::kable(digits = 2)
```

|  estimate|  statistic|  p.value|  parameter|  conf.low|  conf.high| method                                               | alternative |
|---------:|----------:|--------:|----------:|---------:|----------:|:-----------------------------------------------------|:------------|
|      0.65|     239.01|        0|          1|      0.63|       0.66| 1-sample proportions test with continuity correction | two.sided   |

### Estimate the proportion of unsolved homicides for each cities

``` r
output = map(homi_df$unsolve_homi, homi_df$total_homi, prop.test)
prop.test(homi_df$unsolve_homi, homi_df$total_homi)
```

    ## Warning in prop.test(homi_df$unsolve_homi, homi_df$total_homi): Chi-squared
    ## approximation may be incorrect

    ## 
    ##  51-sample test for equality of proportions without continuity
    ##  correction
    ## 
    ## data:  homi_df$unsolve_homi out of homi_df$total_homi
    ## X-squared = 2857.1, df = 50, p-value < 2.2e-16
    ## alternative hypothesis: two.sided
    ## sample estimates:
    ##    prop 1    prop 2    prop 3    prop 4    prop 5    prop 6    prop 7 
    ## 0.3862434 0.3833505 0.6455607 0.4622642 0.4337500 0.5048860 0.6122841 
    ##    prop 8    prop 9   prop 10   prop 11   prop 12   prop 13   prop 14 
    ## 0.2998544 0.7358627 0.4452450 0.5304428 0.4811742 0.5416667 0.5883287 
    ##   prop 15   prop 16   prop 17   prop 18   prop 19   prop 20   prop 21 
    ## 0.3659420 0.4644809 0.3470226 0.5074779 0.4493192 0.5111301 0.4084034 
    ##   prop 22   prop 23   prop 24   prop 25   prop 26   prop 27   prop 28 
    ## 0.4141926 0.4126984 0.4900310 0.4531250 0.3190225 0.6048387 0.3614350 
    ##   prop 29   prop 30   prop 31   prop 32   prop 33   prop 34   prop 35 
    ## 0.5109290 0.3624511 0.6485356 0.3875598 0.5364308 0.4851190 0.4132029 
    ##   prop 36   prop 37   prop 38   prop 39   prop 40   prop 41   prop 42 
    ## 0.4478103 0.5514223 0.5340729 0.2634033 0.3696809 0.4285714 0.6181818 
    ##   prop 43   prop 44   prop 45   prop 46   prop 47   prop 48   prop 49 
    ## 0.3796095 0.5067873 0.4674797 0.5396541 0.5990991 0.4567308 0.0000000 
    ##   prop 50   prop 51 
    ## 0.3310463 0.4379182
