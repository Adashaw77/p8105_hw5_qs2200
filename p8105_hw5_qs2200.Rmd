---
title: "P8105_hw5_qs2200"
author: "Qi Shao"
date: "11/6/2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(purrr)
```

## Problem 1

### Dataframe contains file names
```{r problem 1.1}
zip_file = tibble(file_name = list.files("./data/problem1"))
```

### Read data
```{r problem 1.2, message = F}
read_file = function(x){
  
  x = str_c("./data/problem1/", x)
  read_csv(x)
  
}

zip_file = 
  zip_file %>%
  mutate(data = map(zip_file$file_name, read_file))
```

### Tidy data
```{r problem 1.3}
zip_file = 
  unnest(zip_file) %>%
  separate(file_name, into =c("arm", "id"), sep = "_") %>%
  separate(id, into =c("id", "other"), sep = ".csv") %>%
  gather(key = week, value = observation, week_1:week_8) %>%
  separate(week, into = c("rm", "week"), sep = "_") %>%
  select(-other, -rm )

zip_file
```

### Make a spaghetti plot
```{r problem 1.4}
zip_file %>%
  mutate(week = as.numeric(week))%>%
  ggplot(aes(x = week, y = observation, color = id)) +
  geom_line()+
  facet_grid(~arm)+
  viridis::scale_color_viridis(
    name = "ID", 
    discrete = TRUE
  )+
  theme_minimal() 
```

From this spaghetti plot, we can see that the observations of control arm remain stable during the 8 weeks, but in experimental arm, the value of observations rise obviously as time went on. So we can conclude that there is a association between experiment variable and observation.

## Problem 2

### Describe the raw data
```{r problem 2.1, message=F}
homi_df = read_csv("./data/homicide-data.csv") 
```

The dataset contains `r ncol(homi_df)` variables, including the id and reported time of cases, the identity of victims(name, age, sex and race), as well as the position of homicides(state, city, longitude and latitude). It also contains the disposition status of homicides.

There are `r nrow(homi_df)` homicides across 50 cities in the dataset.

### Tidy and summarise the data
```{r problem 2.2}
homi_df = 
  homi_df%>%
  mutate(city_state = str_c(city, ", ", state)) %>%
  group_by(city_state, disposition) %>%
  summarise(total= n()) %>%
  spread(key = disposition, value = total) %>%
  janitor::clean_names() %>%
  mutate(total_homi = rowSums(cbind(closed_by_arrest, closed_without_arrest, open_no_arrest), na.rm = T), unsolve_homi = rowSums(cbind(closed_without_arrest, open_no_arrest), na.rm = T)) %>%
  select(- closed_by_arrest, - closed_without_arrest, -open_no_arrest)
```

In the description of the dataset, we know that it contains homicides from 50 cities, but after summarising total number homicides of each city, there are `r nrow(homi_df)` total numbers. In the row of "Tulsa, AL", there is only one homicide. Because we know that Tulsa is actually in OK, and the longitude and latitude also shows that this homicide was happened in Tulsa, OK. So it might be a typing mistake in location. We should exclude it in further analysis of the data.

```{r problem 2.3}
homi_df = homi_df[-49,]
```
### Estimate the proportion of unsolved homicides in Baltimore
```{r problem 2.4}
baltimore_df = 
  homi_df %>%
  filter(city_state == "Baltimore, MD")

  broom::tidy(prop.test(baltimore_df$unsolve_homi, baltimore_df$total_homi)) %>%
  select(estimate, conf.low, conf.high) %>%
  knitr::kable()
```

### Estimate the proportion of unsolved homicides for each cities
```{r problem 2.5}
prop_zip = function(x,y){
  
  prop.test(x,y) %>%
    broom::tidy()
}

city_prop =
  ungroup(homi_df) %>%
  mutate(prop_test = map2(homi_df$unsolve_homi, homi_df$total_homi, prop_zip))%>%
  unnest() %>%
  select(city_state, estimate,conf.low, conf.high) %>%
  mutate(city_state = fct_reorder(city_state, estimate))
  
```

### Make a error bar plot
```{r problem 2.6, fig.height=8}
ggplot(data = city_prop,aes(x = city_state,y = estimate)) + 
  geom_point() +
  geom_errorbar(aes(ymin = conf.low,ymax = conf.high))+
  coord_flip()+
  theme_minimal()+
  labs(title = "Estimate and 95% CI of unsolved homicides proportion for each city", 
         x = "City and State", 
         y = "Confidence interval") 
```
